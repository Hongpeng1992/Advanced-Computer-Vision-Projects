{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Section One â€“ Image Captioning with Tensorflow</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load essential libraries\n",
    "import math\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Tensorflow/Google Brain base code\n",
    "# https://github.com/tensorflow/models/tree/master/research/im2txt\n",
    "\n",
    "from im2txt import configuration\n",
    "from im2txt import inference_wrapper\n",
    "from im2txt.inference_utils import caption_generator\n",
    "from im2txt.inference_utils import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell our function where to find the trained model and vocabulary\n",
    "checkpoint_path = './model'\n",
    "vocab_file = './model/word_counts.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function we'll call to produce our captions \n",
    "#    given input file name(s) -- separate file names by a ,\n",
    "#                                 if more than one\n",
    "\n",
    "def gen_caption(input_files):\n",
    "    # only print serious log messages\n",
    "    tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "    # load our pretrained model\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        model = inference_wrapper.InferenceWrapper()\n",
    "        restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n",
    "                                                 checkpoint_path)\n",
    "    g.finalize()\n",
    "\n",
    "    # Create the vocabulary.\n",
    "    vocab = vocabulary.Vocabulary(vocab_file)\n",
    "\n",
    "    filenames = []\n",
    "    for file_pattern in input_files.split(\",\"):\n",
    "        filenames.extend(tf.gfile.Glob(file_pattern))\n",
    "    tf.logging.info(\"Running caption generation on %d files matching %s\",\n",
    "                    len(filenames), input_files)\n",
    "\n",
    "    with tf.Session(graph=g) as sess:\n",
    "        # Load the model from checkpoint.\n",
    "        restore_fn(sess)\n",
    "\n",
    "    # Prepare the caption generator. Here we are implicitly using the default\n",
    "    # beam search parameters. See caption_generator.py for a description of the\n",
    "    # available beam search parameters.\n",
    "        generator = caption_generator.CaptionGenerator(model, vocab)\n",
    "        \n",
    "        captionlist = []\n",
    "\n",
    "        for filename in filenames:\n",
    "            with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "                image = f.read()\n",
    "            captions = generator.beam_search(sess, image)\n",
    "            print(\"Captions for image %s:\" % os.path.basename(filename))\n",
    "            for i, caption in enumerate(captions):\n",
    "                # Ignore begin and end words.\n",
    "                sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "                sentence = \" \".join(sentence)\n",
    "                print(\"  %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))\n",
    "                captionlist.append(sentence)\n",
    "    return captionlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = 'test_images/ballons.jpeg'\n",
    "\n",
    "figure()\n",
    "imshow(imread(testfile))\n",
    "\n",
    "capts = gen_caption(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = 'test_images/ballons.jpeg,test_images/bike.jpeg,test_images/dog.jpeg,test_images/fireworks.jpeg,test_images/football.jpeg,test_images/giraffes.jpeg,test_images/headphones.jpeg,test_images/laughing.jpeg,test_images/objects.jpeg,test_images/snowboard.jpeg,test_images/surfing.jpeg'\n",
    "\n",
    "capts = gen_caption(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<p><p><p><p><p>\n",
    "<b>Retraining the image captioner</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First download pretrained Inception (v3) model\n",
    "\n",
    "import webbrowser \n",
    "webbrowser.open(\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\")\n",
    "\n",
    "# Completely unzip tar.gz file to get inception_v3.ckpt,\n",
    "# --recommend storing in im2txt/data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now gather and prepare the mscoco data\n",
    "\n",
    "# Comment out cd magic command if already in data directory\n",
    "%cd im2txt/data\n",
    "# This command will take an hour or more to run typically.\n",
    "# Note, you will need a lot of HD space (>100 GB)!\n",
    "%run build_mscoco_data.py\n",
    "\n",
    "# At this point you have files in im2txt/data/mscoco/raw-data that you can train\n",
    "#   on, or you can substitute your own data\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load needed modules\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from im2txt import configuration\n",
    "from im2txt import show_and_tell_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define (but don't run yet) our captioning training function\n",
    "def train():\n",
    "    model_config = configuration.ModelConfig()\n",
    "    model_config.input_file_pattern = input_file_pattern\n",
    "    model_config.inception_checkpoint_file = inception_checkpoint_file\n",
    "    training_config = configuration.TrainingConfig()\n",
    "\n",
    "    # Create training directory.\n",
    "    train_dir = train_dir\n",
    "    if not tf.gfile.IsDirectory(train_dir):\n",
    "        tf.logging.info(\"Creating training directory: %s\", train_dir)\n",
    "        tf.gfile.MakeDirs(train_dir)\n",
    "\n",
    "    # Build the TensorFlow graph.\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        # Build the model.\n",
    "        model = show_and_tell_model.ShowAndTellModel(\n",
    "                model_config, mode=\"train\", train_inception=train_inception)\n",
    "        model.build()\n",
    "\n",
    "        # Set up the learning rate.\n",
    "        learning_rate_decay_fn = None\n",
    "        if train_inception:\n",
    "            learning_rate = tf.constant(training_config.train_inception_learning_rate)\n",
    "        else:\n",
    "            learning_rate = tf.constant(training_config.initial_learning_rate)\n",
    "            if training_config.learning_rate_decay_factor > 0:\n",
    "                num_batches_per_epoch = (training_config.num_examples_per_epoch /\n",
    "                                 model_config.batch_size)\n",
    "                decay_steps = int(num_batches_per_epoch *\n",
    "                          training_config.num_epochs_per_decay)\n",
    "\n",
    "                def _learning_rate_decay_fn(learning_rate, global_step):\n",
    "                    return tf.train.exponential_decay(\n",
    "                                      learning_rate,\n",
    "                                      global_step,\n",
    "                                      decay_steps=decay_steps,\n",
    "                                      decay_rate=training_config.learning_rate_decay_factor,\n",
    "                                      staircase=True)\n",
    "\n",
    "                learning_rate_decay_fn = _learning_rate_decay_fn\n",
    "\n",
    "        # Set up the training ops.\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "                                        loss=model.total_loss,\n",
    "                                        global_step=model.global_step,\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        optimizer=training_config.optimizer,\n",
    "                                        clip_gradients=training_config.clip_gradients,\n",
    "                                        learning_rate_decay_fn=learning_rate_decay_fn)\n",
    "\n",
    "        # Set up the Saver for saving and restoring model checkpoints.\n",
    "        saver = tf.train.Saver(max_to_keep=training_config.max_checkpoints_to_keep)\n",
    "\n",
    "    # Run training.\n",
    "    tf.contrib.slim.learning.train(\n",
    "                                train_op,\n",
    "                                train_dir,\n",
    "                                log_every_n_steps=log_every_n_steps,\n",
    "                                graph=g,\n",
    "                                global_step=model.global_step,\n",
    "                                number_of_steps=number_of_steps,\n",
    "                                init_fn=model.init_fn,\n",
    "                                saver=saver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training\n",
    "input_file_pattern = 'im2txt/data/mscoco/train-?????-of-00256'\n",
    "\n",
    "# change these if you put your stuff somewhere else\n",
    "inception_checkpoint_file = 'im2txt/data/inception_v3.ckpt'\n",
    "train_dir = 'im2txt/model'\n",
    "\n",
    "# Don't train inception for initial run\n",
    "train_inception = False\n",
    "number_of_steps = 1000000\n",
    "log_every_n_steps = 1\n",
    "\n",
    "# Now run the training (warning: takes days-to-weeks!!!)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning\n",
    "input_file_pattern = 'im2txt/data/mscoco/train-?????-of-00256'\n",
    "\n",
    "# change these if you put your stuff somewhere else\n",
    "inception_checkpoint_file = 'im2txt/data/inception_v3.ckpt'\n",
    "train_dir = 'im2txt/model'\n",
    "\n",
    "# This will refine our results\n",
    "train_inception = True\n",
    "number_of_steps = 3000000\n",
    "log_every_n_steps = 1\n",
    "\n",
    "# Now run the training (warning: takes even longer than initial training!!!)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you completed this, you can go back to the start of this notebook and \n",
    "#   point checkpoint_path and vocab_file to your generated files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
